{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smrutipunto/NLP/blob/main/Practical1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBlyRTRaJ_K",
        "outputId": "28b2bc4a-82e2-448c-b761-84d91ff0b919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aESx36oXX8SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_preprocessing packages\n",
        "# some text \"Hello\" 'hello'\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ],
      "metadata": {
        "id": "6-CjFowUaQkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGsiKAddaZxD",
        "outputId": "750b4641-bc35-4a1a-da34-9b388bde7fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Tokenization\n",
        "def tokenize(text):\n",
        "    \"\"\"Tokenizes the input text into words.\"\"\"\n",
        "    return word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "-HH7FpVEam44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Stop-words Removal\n",
        "def remove_stopwords(tokens):\n",
        "    \"\"\"Removes stop words from the list of tokens.\"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [word for word in tokens if word.lower() not in stop_words]"
      ],
      "metadata": {
        "id": "WGYKdr5TapHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Text Normalization\n",
        "def normalize(text):\n",
        "    \"\"\"Normalizes the text by converting it to lowercase and removing punctuation.\"\"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    return text"
      ],
      "metadata": {
        "id": "ff5PnNjjayW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing Pipeline Function\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Combines all text preprocessing steps.\"\"\"\n",
        "    normalized_text = normalize(text) # this is goa it has beaches\n",
        "    tokens = tokenize(normalized_text) # this, is,  goa, it, has, beaches\n",
        "    #print(tokens)\n",
        "    filtered_tokens = remove_stopwords(tokens) #goa beaches\n",
        "    return ' '.join(filtered_tokens)  # Return as a single string\n",
        "# preprocess_text(\"This is Goa . It has beaches\")"
      ],
      "metadata": {
        "id": "dDF7Dctga3Ka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f0dcf9de-2a40-4bd3-fdb5-461f789e3ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'goa beaches'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/SMSSpamCollection'\n",
        "output_file_path = 'processed_output.txt'\n",
        "\n",
        "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Process each line and store results\n",
        "processed_lines = [preprocess_text(line.strip()) for line in lines]\n",
        "\n",
        "# Save the processed lines to a new text file\n",
        "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "    for line in processed_lines:\n",
        "        file.write(line + '\\n')\n",
        "\n",
        "print(f\"Text preprocessing completed and saved to '{output_file_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fujN8UwUa5iO",
        "outputId": "5b8b2a48-b277-47d2-c140-fc376d65607b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing completed and saved to 'processed_output.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 lines of the input file\n",
        "print(\"Provided Input (First 5 Lines):\")\n",
        "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "    for _ in range(5):\n",
        "        line = file.readline()\n",
        "        if line:  # Check if there's a line to read\n",
        "            print(line.strip())\n",
        "        else:\n",
        "            break  # Exit if there are fewer than 5 lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x9Pgf-4dI8D",
        "outputId": "066c0e92-4e02-4c60-dfc0-a1c743bfead6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provided Input (First 5 Lines):\n",
            "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "ham\tOk lar... Joking wif u oni...\n",
            "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "ham\tU dun say so early hor... U c already then say...\n",
            "ham\tNah I don't think he goes to usf, he lives around here though\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 lines of the output file\n",
        "print(\"Processed Output (First 5 Lines):\")\n",
        "with open('/content/processed_output.txt', 'r', encoding='utf-8') as file:\n",
        "    for _ in range(5):\n",
        "        line = file.readline()\n",
        "        if line:  # Check if there's a line to read\n",
        "            print(line.strip())\n",
        "        else:\n",
        "            break  # Exit if there are fewer than 5 lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKd8febWcYuO",
        "outputId": "e27edab4-aeea-474b-dc52-d150355ce863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Output (First 5 Lines):\n",
            "ham go jurong point crazy available bugis n great world la e buffet cine got amore wat\n",
            "ham ok lar joking wif u oni\n",
            "spam free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s\n",
            "ham u dun say early hor u c already say\n",
            "ham nah dont think goes usf lives around though\n"
          ]
        }
      ]
    }
  ]
}