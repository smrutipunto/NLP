{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smrutipunto/NLP/blob/main/Practical_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentimental Analysis"
      ],
      "metadata": {
        "id": "JJ8C-4VMaK9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov9I70CieRrn",
        "outputId": "92ed21cc-bd02-4fc8-b6de-334b9045fc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas nltk scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Download NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/TestLarge.csv')\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words and non-alphabetic words\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['Processed_Review'] = df['Review'].apply(preprocess_text)\n",
        "\n",
        "# Features and labels\n",
        "X = df['Processed_Review']\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Model training\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label='Positive', average='binary')\n",
        "recall = recall_score(y_test, y_pred, pos_label='Positive', average='binary')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "\n",
        "# Sample predictions\n",
        "sample_reviews = [\n",
        "    \"This product is amazing!\",\n",
        "    \"I'm really disappointed with my purchase.\",\n",
        "    \"It does exactly what I needed.\",\n",
        "    \"Not worth the price.\",\n",
        "    \"I would buy this again in a heartbeat!\"\n",
        "]\n",
        "\n",
        "# Preprocess and vectorize sample reviews\n",
        "sample_reviews_processed = [preprocess_text(review) for review in sample_reviews]\n",
        "sample_reviews_vectorized = vectorizer.transform(sample_reviews_processed)\n",
        "\n",
        "# Predict sentiment\n",
        "sample_predictions = model.predict(sample_reviews_vectorized)\n",
        "\n",
        "# Display predictions\n",
        "for review, sentiment in zip(sample_reviews, sample_predictions):\n",
        "    print(f'Review: \"{review}\" - Predicted Sentiment: {sentiment}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLBbEqzgeWKv",
        "outputId": "8180f277-8e48-4379-c7d9-9e956686be3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Precision: 0.90\n",
            "Recall: 1.00\n",
            "Review: \"This product is amazing!\" - Predicted Sentiment: Positive\n",
            "Review: \"I'm really disappointed with my purchase.\" - Predicted Sentiment: Negative\n",
            "Review: \"It does exactly what I needed.\" - Predicted Sentiment: Positive\n",
            "Review: \"Not worth the price.\" - Predicted Sentiment: Positive\n",
            "Review: \"I would buy this again in a heartbeat!\" - Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive Negative Neutral\n",
        "    1       0        0\n",
        "    0       1        0\n",
        "    0       0        1\n",
        "\n",
        "    [[[0.2 ...],[0.2 0.3 .4], []],[[],[],[]]]"
      ],
      "metadata": {
        "id": "-tAbTVpps0G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lx_rKRELv2HK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}