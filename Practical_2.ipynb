{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smrutipunto/NLP/blob/main/Practical_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXr1LKJiyAn4",
        "outputId": "82a9e552-35f2-456b-91b1-23888be15a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  messages    processed_messages\n",
            "0      The cats are playing in the garden.       cat play garden\n",
            "1  He is running quickly to catch the bus.  run quickli catch bu\n",
            "2        The boys are enjoying their game.        boy enjoy game\n",
            "3                  She was reading a book.             read book\n",
            "4        I love to eat apples and bananas.  love eat appl banana\n",
            "\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Practical 2\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "data = {'messages': [\n",
        "    \"The cats are playing in the garden.\",\n",
        "    \"He is running quickly to catch the bus.\",\n",
        "    \"The boys are enjoying their game.\",\n",
        "    \"She was reading a book.\",\n",
        "    \"I love to eat apples and bananas.\"\n",
        "]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize the stemmer and stop words\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Stop-words Removal\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Text Normalization (Lowercasing and Removing punctuation)\n",
        "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
        "\n",
        "    # Stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the pre-processing pipeline\n",
        "df['processed_messages'] = df['messages'].apply(preprocess_text)\n",
        "\n",
        "# Display the result\n",
        "print(df[['messages', 'processed_messages']])\n",
        "print(\"\\n \\n\")\n",
        "def another_stem(val):\n",
        "  #intialise\n",
        "  #use\n",
        "  return\n"
      ]
    }
  ]
}